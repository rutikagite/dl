{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"NbU0bG09qMhK","outputId":"f261fd1b-3a4d-4757-fdfe-da8b3b1bbd80"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n","Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n","Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"]}],"source":["!pip install tensorflow matplotlib numpy\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"zy79zzStoLNK"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.datasets import imdb\n","from tensorflow.keras.preprocessing import sequence\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"yA5hIzrAqZVB","outputId":"e4a73e8b-6907-4975-8e85-836c1ece2401"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading data...\n","25000 train sequences\n","25000 test sequences\n"]}],"source":["# Vocabulary size (top words only)\n","max_features = 10000\n","maxlen = 200  # each review cut/padded to 200 words\n","\n","print(\"Loading data...\")\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n","\n","print(len(x_train), \"train sequences\")\n","print(len(x_test), \"test sequences\")\n","\n","# Pad sequences to fixed length\n","x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n","x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"4jTLd7glqeM5","outputId":"6d2a38a6-d7f4-4356-843c-346e17c1aae6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading data...\n","25000 train sequences\n","25000 test sequences\n"]}],"source":["# Vocabulary size (top words only)\n","max_features = 10000\n","maxlen = 200  # each review cut/padded to 200 words\n","\n","print(\"Loading data...\")\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n","\n","print(len(x_train), \"train sequences\")\n","print(len(x_test), \"test sequences\")\n","\n","# Pad sequences to fixed length\n","x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n","x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9cBXzsR6qkwK","outputId":"fe933dd1-9e2d-40b9-f352-73f39c47eaec"},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"sequential_1\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n","â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n","â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n","â”‚ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n","â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","</pre>\n"],"text/plain":["â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n","â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n","â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n","â”‚ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)        â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n","â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["None\n"]}],"source":["model = Sequential()\n","model.add(Embedding(max_features, 128))        # word embeddings\n","model.add(SimpleRNN(128, dropout=0.2))         # Simple RNN\n","model.add(Dense(1, activation='sigmoid'))      # output layer (binary)\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","\n","print(model.summary())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VeMq6vanqq7J"},"outputs":[],"source":["history = model.fit(x_train, y_train,\n","                    batch_size=32,\n","                    epochs=5,\n","                    validation_data=(x_test, y_test))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9XFGCyfzq4Z7"},"outputs":[],"source":["plt.plot(history.history['accuracy'], label='Train Accuracy')\n","plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Accuracy\")\n","plt.legend()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mD8RqERYrAFR"},"outputs":[],"source":["# ğŸ§  IMDB Sentiment Classification using LSTM\n","import torch, torch.nn as nn, torch.optim as optim\n","from torchtext.datasets import IMDB\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","from torch.utils.data import DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","import matplotlib.pyplot as plt\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(\"Device:\", device)\n","\n","# 1ï¸âƒ£ Load & preprocess data\n","train_iter, test_iter = IMDB(split=('train', 'test'))\n","tokenizer = get_tokenizer('basic_english')\n","\n","def yield_tokens(data_iter):\n","    for label, text in data_iter:\n","        yield tokenizer(text)\n","\n","vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n","vocab.set_default_index(vocab[\"<unk>\"])\n","train_iter, test_iter = IMDB(split=('train', 'test'))\n","\n","def process_batch(batch):\n","    texts = [torch.tensor(vocab(tokenizer(text))) for label, text in batch]\n","    labels = [1 if label == 'pos' else 0 for label, text in batch]\n","    return pad_sequence(texts, batch_first=True), torch.tensor(labels)\n","\n","train_loader = DataLoader(list(train_iter), batch_size=32, shuffle=True, collate_fn=process_batch)\n","test_loader  = DataLoader(list(test_iter), batch_size=32, shuffle=False, collate_fn=process_batch)\n","\n","# 2ï¸âƒ£ Define model\n","class LSTMClassifier(nn.Module):\n","    def __init__(self, vocab_size, embed_dim, hidden_dim):\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, embed_dim)\n","        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n","        self.fc = nn.Linear(hidden_dim, 2)\n","    def forward(self, x):\n","        x = self.embedding(x)\n","        _, (h, _) = self.lstm(x)\n","        return self.fc(h[-1])\n","\n","model = LSTMClassifier(len(vocab), 64, 128).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# 3ï¸âƒ£ Train model\n","train_acc, val_acc = [], []\n","for epoch in range(3):\n","    model.train()\n","    correct = total = loss_sum = 0\n","    for texts, labels in train_loader:\n","        texts, labels = texts.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        out = model(texts)\n","        loss = criterion(out, labels)\n","        loss.backward(); optimizer.step()\n","        loss_sum += loss.item()\n","        correct += (out.argmax(1) == labels).sum().item(); total += labels.size(0)\n","    train_accuracy = 100*correct/total; train_acc.append(train_accuracy)\n","    print(f\"Epoch {epoch+1}: Loss={loss_sum/len(train_loader):.4f}, Train Acc={train_accuracy:.2f}%\")\n","\n","    # Validation\n","    model.eval(); correct = total = 0\n","    with torch.no_grad():\n","        for texts, labels in test_loader:\n","            texts, labels = texts.to(device), labels.to(device)\n","            preds = model(texts).argmax(1)\n","            correct += (preds == labels).sum().item(); total += labels.size(0)\n","    val_accuracy = 100*correct/total; val_acc.append(val_accuracy)\n","    print(f\"Validation Accuracy: {val_accuracy:.2f}%\\n\")\n","\n","# 4ï¸âƒ£ Plot accuracy\n","plt.plot(train_acc, label='Train Acc'); plt.plot(val_acc, label='Val Acc')\n","plt.xlabel('Epochs'); plt.ylabel('Accuracy (%)'); plt.title('LSTM Sentiment Classification')\n","plt.legend(); plt.show()\n","\n","# 5ï¸âƒ£ Example predictions\n","examples = [\n","    \"This movie was amazing and the performances were outstanding!\",\n","    \"The film was boring, I did not like it at all.\",\n","    \"Not great, but not terrible either.\"\n","]\n","model.eval()\n","for text in examples:\n","    tokens = torch.tensor(vocab(tokenizer(text))).unsqueeze(0).to(device)\n","    pred = model(tokens).argmax(1).item()\n","    print(f\"Review: {text}\\nPredicted Sentiment: {'Positive ğŸ˜Š' if pred==1 else 'Negative ğŸ˜'}\\n\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ZtMPOVc5UCx"},"outputs":[],"source":["# Train the model\n","history = model.fit(\n","    x_train,\n","    y_train,\n","    batch_size=64,\n","    epochs=5,\n","    validation_data=(x_test, y_test)\n",")\n","\n","# Evaluate on test set\n","loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n","print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kINyms2bQaVq"},"outputs":[],"source":["pip install torchtext"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}